{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfs_data_preprocess.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ccehshmily/learnDL/blob/master/tfs_data_preprocess.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nWUOC1XO9jrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "88a884b7-ac57-46e0-8895-473adbfe05d6"
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import io\n",
        "import math\n",
        "import os\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "!wget https://raw.githubusercontent.com/ccehshmily/tfs/master/datasource/sampledata/sampleGOOG.txt -O /tmp/sample_data_GOOG.csv"
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-20 05:00:14--  https://raw.githubusercontent.com/ccehshmily/tfs/master/datasource/sampledata/sampleGOOG.txt\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 218008 (213K) [text/plain]\n",
            "Saving to: ‘/tmp/sample_data_GOOG.csv’\n",
            "\n",
            "/tmp/sample_data_GO 100%[===================>] 212.90K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2018-05-20 05:00:14 (5.81 MB/s) - ‘/tmp/sample_data_GOOG.csv’ saved [218008/218008]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YCwRIw88cTkE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2795c0e9-5094-467c-fd7a-9816e761358c"
      },
      "cell_type": "code",
      "source": [
        "# Normalizes a list of values to the [-1, 1] range\n",
        "def normalize_list(list_values):\n",
        "  min_val = min(list_values)\n",
        "  max_val = max(list_values)\n",
        "  avg_val = (min_val + max_val) / 2.0\n",
        "  range_val = (max_val - min_val) / 2.0\n",
        "  return [(val - avg_val) / range_val for val in list_values]\n",
        "\n",
        "def log_linear_normalize_list(list_values):\n",
        "  min_val = min(list_values)\n",
        "  return normalize_list([math.log(x+1.1-min_val) for x in list_values])\n",
        "\n",
        "def log_normalize_list(list_values):\n",
        "  return [math.log(x+1) for x in list_values]\n",
        "\n",
        "# validate method\n",
        "print log_normalize_list([3.8,1,2,3,4,5])"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.5686159179138452, 0.6931471805599453, 1.0986122886681098, 1.3862943611198906, 1.6094379124341003, 1.791759469228055]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bL1Tkjcx9Iu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "fcafd119-3c36-416a-e6e0-c1d9c89e6cf7"
      },
      "cell_type": "code",
      "source": [
        "# Preprocess raw data saved in /tmp/sample_data_[code].csv, extract data from\n",
        "# recent history, and save processed and normailized data to\n",
        "# /tmp/processed_data_[code].csv and /tmp/normalized_data_[code].csv\n",
        "def preprocess_raw_data(code, price_lookback, volume_lookback, change_lookback):\n",
        "  sample_data = open(\"/tmp/sample_data_\" + code + \".csv\", 'r')\n",
        "  sample_data_lines = sample_data.readlines()\n",
        "  sample_data.close()\n",
        "\n",
        "  # Read each line into a map from column name to value\n",
        "  column_titles = sample_data_lines[0][:-1].split(',')\n",
        "  mapped_data = []\n",
        "  for one_line in sample_data_lines[1:]:\n",
        "    one_day_data = {column_titles[i]:one_line[:-1].split(',')[i] for i in range(len(column_titles))}\n",
        "    mapped_data.append(one_day_data)\n",
        "\n",
        "  # Expand each days data by reading from past N days, cannot process the furthest N days\n",
        "  processed_data = open(\"/tmp/processed_data_\" + code + \".csv\", 'w')\n",
        "  expanded_titles = [\"Date\"] + [\"price_\" + str(i) for i in range(price_lookback*4+1)] + [\"volume_\" + str(i) for i in range(volume_lookback)] + [\"change_\" + str(i) for i in range(change_lookback+1)]\n",
        "  processed_data.write(','.join(expanded_titles) + \"\\n\")\n",
        "  for i in range(len(mapped_data) - max(price_lookback, volume_lookback, change_lookback)):\n",
        "    price_history = [mapped_data[i][\"Open\"]]\n",
        "    volume_history = []\n",
        "    change_history = []\n",
        "\n",
        "    for j in range(max(price_lookback, volume_lookback, change_lookback)):\n",
        "      if j < price_lookback:\n",
        "        price_history.append(mapped_data[i+j+1][\"Close\"])\n",
        "        price_history.append(mapped_data[i+j+1][\"High\"])\n",
        "        price_history.append(mapped_data[i+j+1][\"Low\"])\n",
        "        price_history.append(mapped_data[i+j+1][\"Open\"])\n",
        "      if j < volume_lookback:\n",
        "        volume_history.append(mapped_data[i+j+1][\"Volume\"])\n",
        "      if j < change_lookback:\n",
        "        change_history.append(str((float(mapped_data[i+j+1][\"Close\"]) - float(mapped_data[i+j+1][\"Open\"])) / float(mapped_data[i+j+1][\"Open\"]) * 100.00))\n",
        "\n",
        "    # Add today's change, this will be the label that we try to predict\n",
        "    change_history.append(str((float(mapped_data[i][\"Close\"]) - float(mapped_data[i][\"Open\"])) / float(mapped_data[i][\"Open\"]) * 100.00))\n",
        "\n",
        "    one_day_data = [code + \"-\" + mapped_data[i][\"Date\"]] + price_history + volume_history + change_history\n",
        "    processed_data.write(','.join(one_day_data) + \"\\n\")\n",
        "  processed_data.close()\n",
        "\n",
        "  # Normalize data\n",
        "  pre_normalized_file = open(\"/tmp/processed_data_\" + code + \".csv\", 'r')\n",
        "  pre_normalized_data = pre_normalized_file.readlines()\n",
        "  pre_normalized_file.close()\n",
        "\n",
        "  normalized_data = open(\"/tmp/normalized_data_\" + code + \".csv\", 'w')\n",
        "  normalized_data.write(pre_normalized_data[0])\n",
        "  for one_line in pre_normalized_data[1:]:\n",
        "    one_day_data = one_line[:-1].split(',')\n",
        "    price_data = [float(price) for price in one_day_data[1:1+price_lookback*4+1]]\n",
        "    volume_data = [float(volume) for volume in one_day_data[1+price_lookback*4+1:1+price_lookback*4+1+volume_lookback]]\n",
        "    change_data = [float(change) for change in one_day_data[1+price_lookback*4+1+volume_lookback:]]\n",
        "    \n",
        "    nor_price_data = [str(price) for price in normalize_list(price_data)]\n",
        "    nor_volume_data = [str(volume) for volume in normalize_list(volume_data)]\n",
        "    nor_change_data = [str(change) for change in normalize_list(change_data)]\n",
        "    \n",
        "    nor_one_day_data = ','.join([one_day_data[0]] + nor_price_data + nor_volume_data + nor_change_data)\n",
        "    normalized_data.write(nor_one_day_data + \"\\n\")\n",
        "  normalized_data.close()\n",
        "\n",
        "code = \"GOOG\"\n",
        "price_lookback = 10\n",
        "volume_lookback = 25\n",
        "change_lookback = 25\n",
        "\n",
        "preprocess_raw_data(code, price_lookback, volume_lookback, change_lookback)\n",
        "\n",
        "# validate method\n",
        "f1 = open(\"/tmp/processed_data_GOOG.csv\", 'r')\n",
        "f2 = open(\"/tmp/normalized_data_GOOG.csv\", 'r')\n",
        "print f1.readline()\n",
        "print f1.readline()\n",
        "print f2.readline()\n",
        "print f2.readline()\n",
        "print len(f2.readlines())"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date,price_0,price_1,price_2,price_3,price_4,price_5,price_6,price_7,price_8,price_9,price_10,price_11,price_12,price_13,price_14,price_15,price_16,price_17,price_18,price_19,price_20,price_21,price_22,price_23,price_24,price_25,price_26,price_27,price_28,price_29,price_30,price_31,price_32,price_33,price_34,price_35,price_36,price_37,price_38,price_39,price_40,volume_0,volume_1,volume_2,volume_3,volume_4,volume_5,volume_6,volume_7,volume_8,volume_9,volume_10,volume_11,volume_12,volume_13,volume_14,volume_15,volume_16,volume_17,volume_18,volume_19,volume_20,volume_21,volume_22,volume_23,volume_24,change_0,change_1,change_2,change_3,change_4,change_5,change_6,change_7,change_8,change_9,change_10,change_11,change_12,change_13,change_14,change_15,change_16,change_17,change_18,change_19,change_20,change_21,change_22,change_23,change_24,change_25\n",
            "\n",
            "GOOG-2016-05-24,706.859985,704.23999,711.478027,704.179993,706.530029,709.73999,714.580017,700.52002,701.619995,700.320007,706.00,696.799988,702.359985,706.630005,711.599976,700.630005,703.669983,706.22998,721.52002,704.109985,715.98999,716.48999,718.47998,705.650024,709.130005,710.830017,716.661987,709.26001,711.929993,713.309998,719.25,709.00,717.059998,715.289978,724.47998,712.799988,723.409973,723.179993,723.50,715.719971,716.75,1320900,1816000,1656300,1763400,1999500,1316200,1307300,1360700,1686800,1563100,1508400,1826100,1677400,1688600,1531000,1644100,2484300,2851100,3086700,2727200,1955600,5939200,2742500,1525600,2027600,-0.324124793852,1.1573209227,-0.290446216124,0.420654862579,-1.3631489457,1.03788937827,-0.154506202972,-0.522968790681,-1.12246102529,0.897104011161,0.126407865169,1.82422032544,0.534610998401,0.754539830476,-0.647180970964,0.0831410627185,0.334443023001,-2.43413291116,-0.205000925377,-2.38206396363,0.984506107566,-1.03675727997,0.497764035997,-0.703168469657,-2.02466722948,1.8716637355\n",
            "\n",
            "Date,price_0,price_1,price_2,price_3,price_4,price_5,price_6,price_7,price_8,price_9,price_10,price_11,price_12,price_13,price_14,price_15,price_16,price_17,price_18,price_19,price_20,price_21,price_22,price_23,price_24,price_25,price_26,price_27,price_28,price_29,price_30,price_31,price_32,price_33,price_34,price_35,price_36,price_37,price_38,price_39,price_40,volume_0,volume_1,volume_2,volume_3,volume_4,volume_5,volume_6,volume_7,volume_8,volume_9,volume_10,volume_11,volume_12,volume_13,volume_14,volume_15,volume_16,volume_17,volume_18,volume_19,volume_20,volume_21,volume_22,volume_23,volume_24,change_0,change_1,change_2,change_3,change_4,change_5,change_6,change_7,change_8,change_9,change_10,change_11,change_12,change_13,change_14,change_15,change_16,change_17,change_18,change_19,change_20,change_21,change_22,change_23,change_24,change_25\n",
            "\n",
            "GOOG-2016-05-24,-0.273121393966,-0.462427445788,0.0605522573851,-0.466762490394,-0.296962152301,-0.0650284870024,0.284684547597,-0.731211483009,-0.651733497611,-0.745663293544,-0.335259056433,-1.0,-0.598265996609,-0.289738450791,0.0693636038623,-0.723264587649,-0.50361293457,-0.318641999608,0.786129995991,-0.471820873359,0.386561238891,0.422688416962,0.566473863143,-0.360546346979,-0.109102560434,0.0137307120609,0.435115949455,-0.0997091328639,0.0932087697135,0.192920142462,0.62211116246,-0.118495988005,0.463873977998,0.335982322538,1.0,0.156069698286,0.922687333147,0.906070276321,0.929192176067,0.367051189899,0.441475272103,-0.994127679786,-0.780349316695,-0.849305900386,-0.8030613787,-0.701116172629,-0.996157084566,-1.0,-0.976942507394,-0.83613635873,-0.889548565384,-0.913167382716,-0.77598825536,-0.840195168289,-0.835359139878,-0.903408968242,-0.854573717049,-0.491785228524,-0.333405298042,-0.231675986096,-0.386903862346,-0.72007167685,1.0,-0.380297502105,-0.905740624798,-0.688982922775,-0.019922076931,0.668194821344,-0.00427871032932,0.326020714867,-0.50253852964,0.612720048971,0.0588640826576,-0.112283148828,-0.390741368668,0.547326636944,0.189345891806,0.97796300478,0.378952214041,0.481106983587,-0.169978479322,0.169248889555,0.285976167179,-1.0,0.0354097830013,-0.975814488327,0.587924047169,-0.350932825741,0.361837164062,-0.195984119294,-0.809807236485,1.0\n",
            "\n",
            "2936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rRsVDUC0vJGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "ea234f06-d95f-4e12-d6ed-b6ac896bb135"
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "normalized_google_data = pd.read_csv(\"/tmp/normalized_data_GOOG.csv\", sep=\",\")\n",
        "display.display(normalized_google_data.describe())"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        price_0   price_1   price_2   price_3   price_4   price_5   price_6  \\\n",
              "count 2937.0000 2937.0000 2937.0000 2937.0000 2937.0000 2937.0000 2937.0000   \n",
              "mean     0.1346    0.1072    0.3742   -0.1676    0.1138    0.0866    0.3538   \n",
              "std      0.6400    0.6095    0.5514    0.5855    0.5515    0.5367    0.4955   \n",
              "min     -1.0000   -1.0000   -0.9590   -1.0000   -1.0000   -1.0000   -0.9590   \n",
              "25%     -0.4475   -0.4484   -0.1306   -0.7399   -0.3930   -0.3892   -0.0592   \n",
              "50%      0.2230    0.1709    0.4865   -0.1353    0.1821    0.1403    0.4352   \n",
              "75%      0.7275    0.6814    0.9075    0.3761    0.6045    0.5652    0.7914   \n",
              "max      1.0000    1.0000    1.0000    0.8410    1.0000    0.9906    1.0000   \n",
              "\n",
              "        price_7   price_8   price_9    ...      change_16  change_17  \\\n",
              "count 2937.0000 2937.0000 2937.0000    ...      2937.0000  2937.0000   \n",
              "mean    -0.1869    0.0943    0.0675    ...         0.0033     0.0021   \n",
              "std      0.5252    0.5072    0.4998    ...         0.5139     0.5149   \n",
              "min     -1.0000   -1.0000   -1.0000    ...        -1.0000    -1.0000   \n",
              "25%     -0.6519   -0.3242   -0.3342    ...        -0.3557    -0.3578   \n",
              "50%     -0.1621    0.1296    0.0961    ...         0.0078     0.0050   \n",
              "75%      0.2708    0.5241    0.4862    ...         0.3690     0.3718   \n",
              "max      0.8200    1.0000    0.9862    ...         1.0000     1.0000   \n",
              "\n",
              "       change_18  change_19  change_20  change_21  change_22  change_23  \\\n",
              "count  2937.0000  2937.0000  2937.0000  2937.0000  2937.0000  2937.0000   \n",
              "mean      0.0021     0.0026     0.0028     0.0014     0.0014     0.0019   \n",
              "std       0.5163     0.5160     0.5181     0.5189     0.5195     0.5221   \n",
              "min      -1.0000    -1.0000    -1.0000    -1.0000    -1.0000    -1.0000   \n",
              "25%      -0.3672    -0.3617    -0.3616    -0.3600    -0.3610    -0.3617   \n",
              "50%       0.0069     0.0061     0.0080     0.0118     0.0123     0.0185   \n",
              "75%       0.3753     0.3770     0.3813     0.3807     0.3760     0.3794   \n",
              "max       1.0000     1.0000     1.0000     1.0000     1.0000     1.0000   \n",
              "\n",
              "       change_24  change_25  \n",
              "count  2937.0000  2937.0000  \n",
              "mean      0.0019    -0.0042  \n",
              "std       0.5230     0.5107  \n",
              "min      -1.0000    -1.0000  \n",
              "25%      -0.3553    -0.3617  \n",
              "50%       0.0167    -0.0106  \n",
              "75%       0.3766     0.3584  \n",
              "max       1.0000     1.0000  \n",
              "\n",
              "[8 rows x 92 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price_0</th>\n",
              "      <th>price_1</th>\n",
              "      <th>price_2</th>\n",
              "      <th>price_3</th>\n",
              "      <th>price_4</th>\n",
              "      <th>price_5</th>\n",
              "      <th>price_6</th>\n",
              "      <th>price_7</th>\n",
              "      <th>price_8</th>\n",
              "      <th>price_9</th>\n",
              "      <th>...</th>\n",
              "      <th>change_16</th>\n",
              "      <th>change_17</th>\n",
              "      <th>change_18</th>\n",
              "      <th>change_19</th>\n",
              "      <th>change_20</th>\n",
              "      <th>change_21</th>\n",
              "      <th>change_22</th>\n",
              "      <th>change_23</th>\n",
              "      <th>change_24</th>\n",
              "      <th>change_25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "      <td>2937.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.1346</td>\n",
              "      <td>0.1072</td>\n",
              "      <td>0.3742</td>\n",
              "      <td>-0.1676</td>\n",
              "      <td>0.1138</td>\n",
              "      <td>0.0866</td>\n",
              "      <td>0.3538</td>\n",
              "      <td>-0.1869</td>\n",
              "      <td>0.0943</td>\n",
              "      <td>0.0675</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0021</td>\n",
              "      <td>0.0021</td>\n",
              "      <td>0.0026</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.6400</td>\n",
              "      <td>0.6095</td>\n",
              "      <td>0.5514</td>\n",
              "      <td>0.5855</td>\n",
              "      <td>0.5515</td>\n",
              "      <td>0.5367</td>\n",
              "      <td>0.4955</td>\n",
              "      <td>0.5252</td>\n",
              "      <td>0.5072</td>\n",
              "      <td>0.4998</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5139</td>\n",
              "      <td>0.5149</td>\n",
              "      <td>0.5163</td>\n",
              "      <td>0.5160</td>\n",
              "      <td>0.5181</td>\n",
              "      <td>0.5189</td>\n",
              "      <td>0.5195</td>\n",
              "      <td>0.5221</td>\n",
              "      <td>0.5230</td>\n",
              "      <td>0.5107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.9590</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.9590</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.4475</td>\n",
              "      <td>-0.4484</td>\n",
              "      <td>-0.1306</td>\n",
              "      <td>-0.7399</td>\n",
              "      <td>-0.3930</td>\n",
              "      <td>-0.3892</td>\n",
              "      <td>-0.0592</td>\n",
              "      <td>-0.6519</td>\n",
              "      <td>-0.3242</td>\n",
              "      <td>-0.3342</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.3557</td>\n",
              "      <td>-0.3578</td>\n",
              "      <td>-0.3672</td>\n",
              "      <td>-0.3617</td>\n",
              "      <td>-0.3616</td>\n",
              "      <td>-0.3600</td>\n",
              "      <td>-0.3610</td>\n",
              "      <td>-0.3617</td>\n",
              "      <td>-0.3553</td>\n",
              "      <td>-0.3617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.2230</td>\n",
              "      <td>0.1709</td>\n",
              "      <td>0.4865</td>\n",
              "      <td>-0.1353</td>\n",
              "      <td>0.1821</td>\n",
              "      <td>0.1403</td>\n",
              "      <td>0.4352</td>\n",
              "      <td>-0.1621</td>\n",
              "      <td>0.1296</td>\n",
              "      <td>0.0961</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0069</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0080</td>\n",
              "      <td>0.0118</td>\n",
              "      <td>0.0123</td>\n",
              "      <td>0.0185</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>-0.0106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.7275</td>\n",
              "      <td>0.6814</td>\n",
              "      <td>0.9075</td>\n",
              "      <td>0.3761</td>\n",
              "      <td>0.6045</td>\n",
              "      <td>0.5652</td>\n",
              "      <td>0.7914</td>\n",
              "      <td>0.2708</td>\n",
              "      <td>0.5241</td>\n",
              "      <td>0.4862</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.3718</td>\n",
              "      <td>0.3753</td>\n",
              "      <td>0.3770</td>\n",
              "      <td>0.3813</td>\n",
              "      <td>0.3807</td>\n",
              "      <td>0.3760</td>\n",
              "      <td>0.3794</td>\n",
              "      <td>0.3766</td>\n",
              "      <td>0.3584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8410</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9906</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8200</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9862</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 92 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MJtRqgvo0Src",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "040b175a-cc93-4f0b-fba6-b0d8351166c9"
      },
      "cell_type": "code",
      "source": [
        "google_data = normalized_google_data.head(1500)\n",
        "google_data = google_data.reindex(np.random.permutation(google_data.index))\n",
        "google_data.head()"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>price_0</th>\n",
              "      <th>price_1</th>\n",
              "      <th>price_2</th>\n",
              "      <th>price_3</th>\n",
              "      <th>price_4</th>\n",
              "      <th>price_5</th>\n",
              "      <th>price_6</th>\n",
              "      <th>price_7</th>\n",
              "      <th>price_8</th>\n",
              "      <th>...</th>\n",
              "      <th>change_16</th>\n",
              "      <th>change_17</th>\n",
              "      <th>change_18</th>\n",
              "      <th>change_19</th>\n",
              "      <th>change_20</th>\n",
              "      <th>change_21</th>\n",
              "      <th>change_22</th>\n",
              "      <th>change_23</th>\n",
              "      <th>change_24</th>\n",
              "      <th>change_25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>GOOG-2012-02-24</td>\n",
              "      <td>-0.0452</td>\n",
              "      <td>-0.1682</td>\n",
              "      <td>0.0134</td>\n",
              "      <td>-0.7399</td>\n",
              "      <td>-0.0799</td>\n",
              "      <td>0.0134</td>\n",
              "      <td>0.8908</td>\n",
              "      <td>-0.1087</td>\n",
              "      <td>0.4124</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.5244</td>\n",
              "      <td>-0.2935</td>\n",
              "      <td>0.5981</td>\n",
              "      <td>-0.6216</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.7500</td>\n",
              "      <td>-0.3040</td>\n",
              "      <td>-0.6698</td>\n",
              "      <td>-0.3783</td>\n",
              "      <td>-0.0367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1117</th>\n",
              "      <td>GOOG-2011-12-13</td>\n",
              "      <td>0.8758</td>\n",
              "      <td>0.7425</td>\n",
              "      <td>0.7738</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.6037</td>\n",
              "      <td>0.8228</td>\n",
              "      <td>0.8904</td>\n",
              "      <td>0.4111</td>\n",
              "      <td>0.4503</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.8677</td>\n",
              "      <td>-0.2172</td>\n",
              "      <td>0.1129</td>\n",
              "      <td>0.2096</td>\n",
              "      <td>0.3716</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.4247</td>\n",
              "      <td>0.0828</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>-0.4015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>GOOG-2015-03-05</td>\n",
              "      <td>0.9144</td>\n",
              "      <td>0.8469</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.6275</td>\n",
              "      <td>0.7855</td>\n",
              "      <td>0.8580</td>\n",
              "      <td>0.9296</td>\n",
              "      <td>0.5665</td>\n",
              "      <td>0.7274</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.2041</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0453</td>\n",
              "      <td>-0.5974</td>\n",
              "      <td>-0.1160</td>\n",
              "      <td>-0.3951</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>-0.2154</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.1757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1492</th>\n",
              "      <td>GOOG-2010-06-21</td>\n",
              "      <td>0.6475</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.8583</td>\n",
              "      <td>0.5430</td>\n",
              "      <td>0.8016</td>\n",
              "      <td>0.6581</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.4579</td>\n",
              "      <td>0.8571</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.5365</td>\n",
              "      <td>0.5927</td>\n",
              "      <td>-0.3205</td>\n",
              "      <td>0.1555</td>\n",
              "      <td>-0.7796</td>\n",
              "      <td>-0.1915</td>\n",
              "      <td>-0.8508</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>-0.2159</td>\n",
              "      <td>-0.8467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1353</th>\n",
              "      <td>GOOG-2011-01-06</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8273</td>\n",
              "      <td>0.9625</td>\n",
              "      <td>-0.1399</td>\n",
              "      <td>-0.1378</td>\n",
              "      <td>0.0820</td>\n",
              "      <td>0.5174</td>\n",
              "      <td>-0.1324</td>\n",
              "      <td>0.4574</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.7454</td>\n",
              "      <td>-0.5072</td>\n",
              "      <td>-0.7291</td>\n",
              "      <td>-0.5843</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.7108</td>\n",
              "      <td>0.2026</td>\n",
              "      <td>0.1410</td>\n",
              "      <td>-0.1464</td>\n",
              "      <td>0.0556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 93 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Date  price_0  price_1  price_2  price_3  price_4  price_5  \\\n",
              "1068  GOOG-2012-02-24  -0.0452  -0.1682   0.0134  -0.7399  -0.0799   0.0134   \n",
              "1117  GOOG-2011-12-13   0.8758   0.7425   0.7738   0.5408   0.6037   0.8228   \n",
              "308   GOOG-2015-03-05   0.9144   0.8469   1.0000   0.6275   0.7855   0.8580   \n",
              "1492  GOOG-2010-06-21   0.6475   0.6552   0.8583   0.5430   0.8016   0.6581   \n",
              "1353  GOOG-2011-01-06   1.0000   0.8273   0.9625  -0.1399  -0.1378   0.0820   \n",
              "\n",
              "      price_6  price_7  price_8    ...      change_16  change_17  change_18  \\\n",
              "1068   0.8908  -0.1087   0.4124    ...        -0.5244    -0.2935     0.5981   \n",
              "1117   0.8904   0.4111   0.4503    ...        -0.8677    -0.2172     0.1129   \n",
              "308    0.9296   0.5665   0.7274    ...        -0.2041     0.0167     0.0453   \n",
              "1492   1.0000   0.4579   0.8571    ...        -0.5365     0.5927    -0.3205   \n",
              "1353   0.5174  -0.1324   0.4574    ...        -0.7454    -0.5072    -0.7291   \n",
              "\n",
              "      change_19  change_20  change_21  change_22  change_23  change_24  \\\n",
              "1068    -0.6216    -1.0000    -0.7500    -0.3040    -0.6698    -0.3783   \n",
              "1117     0.2096     0.3716    -1.0000    -0.4247     0.0828     1.0000   \n",
              "308     -0.5974    -0.1160    -0.3951     1.0000    -0.2154    -1.0000   \n",
              "1492     0.1555    -0.7796    -0.1915    -0.8508     0.0166    -0.2159   \n",
              "1353    -0.5843    -1.0000    -0.7108     0.2026     0.1410    -0.1464   \n",
              "\n",
              "      change_25  \n",
              "1068    -0.0367  \n",
              "1117    -0.4015  \n",
              "308     -0.1757  \n",
              "1492    -0.8467  \n",
              "1353     0.0556  \n",
              "\n",
              "[5 rows x 93 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "metadata": {
        "id": "UX6PkUBe01QT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_labels_and_features(dataset, price_lookback, volume_lookback, change_lookback):\n",
        "  labels = dataset[\"change_\" + str(change_lookback)].apply(lambda x: int(max(1, math.ceil((x+1)*4))-1)).apply(np.int64)\n",
        "\n",
        "  # DataFrame.loc index ranges are inclusive at both ends.\n",
        "  features = dataset.loc[:,\"price_0\":\"change_\" + str(change_lookback-1)]\n",
        "\n",
        "  return labels, features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JEmKzGCX1wiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "63858f8d-c5d8-47bf-d144-b9f67cbbcfda"
      },
      "cell_type": "code",
      "source": [
        "training_targets, training_examples = parse_labels_and_features(google_data[:1200], price_lookback, volume_lookback, change_lookback)\n",
        "training_examples.describe()"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price_0</th>\n",
              "      <th>price_1</th>\n",
              "      <th>price_2</th>\n",
              "      <th>price_3</th>\n",
              "      <th>price_4</th>\n",
              "      <th>price_5</th>\n",
              "      <th>price_6</th>\n",
              "      <th>price_7</th>\n",
              "      <th>price_8</th>\n",
              "      <th>price_9</th>\n",
              "      <th>...</th>\n",
              "      <th>change_15</th>\n",
              "      <th>change_16</th>\n",
              "      <th>change_17</th>\n",
              "      <th>change_18</th>\n",
              "      <th>change_19</th>\n",
              "      <th>change_20</th>\n",
              "      <th>change_21</th>\n",
              "      <th>change_22</th>\n",
              "      <th>change_23</th>\n",
              "      <th>change_24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "      <td>1200.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.1419</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.3868</td>\n",
              "      <td>-0.1542</td>\n",
              "      <td>0.1316</td>\n",
              "      <td>0.1095</td>\n",
              "      <td>0.3698</td>\n",
              "      <td>-0.1635</td>\n",
              "      <td>0.1161</td>\n",
              "      <td>0.0969</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0103</td>\n",
              "      <td>0.0091</td>\n",
              "      <td>0.0291</td>\n",
              "      <td>0.0147</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0099</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.6372</td>\n",
              "      <td>0.6124</td>\n",
              "      <td>0.5525</td>\n",
              "      <td>0.5935</td>\n",
              "      <td>0.5528</td>\n",
              "      <td>0.5417</td>\n",
              "      <td>0.4996</td>\n",
              "      <td>0.5345</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.5085</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5245</td>\n",
              "      <td>0.5203</td>\n",
              "      <td>0.5195</td>\n",
              "      <td>0.5216</td>\n",
              "      <td>0.5202</td>\n",
              "      <td>0.5312</td>\n",
              "      <td>0.5292</td>\n",
              "      <td>0.5298</td>\n",
              "      <td>0.5230</td>\n",
              "      <td>0.5245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.9991</td>\n",
              "      <td>-0.9590</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.9986</td>\n",
              "      <td>-0.9590</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.9985</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.4211</td>\n",
              "      <td>-0.4261</td>\n",
              "      <td>-0.1056</td>\n",
              "      <td>-0.7430</td>\n",
              "      <td>-0.3686</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>-0.0497</td>\n",
              "      <td>-0.6371</td>\n",
              "      <td>-0.3067</td>\n",
              "      <td>-0.3238</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.3786</td>\n",
              "      <td>-0.3606</td>\n",
              "      <td>-0.3430</td>\n",
              "      <td>-0.3613</td>\n",
              "      <td>-0.3517</td>\n",
              "      <td>-0.3861</td>\n",
              "      <td>-0.3787</td>\n",
              "      <td>-0.3619</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>-0.3486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.2509</td>\n",
              "      <td>0.1884</td>\n",
              "      <td>0.5193</td>\n",
              "      <td>-0.0969</td>\n",
              "      <td>0.2314</td>\n",
              "      <td>0.1769</td>\n",
              "      <td>0.4765</td>\n",
              "      <td>-0.1232</td>\n",
              "      <td>0.1854</td>\n",
              "      <td>0.1549</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0321</td>\n",
              "      <td>0.0386</td>\n",
              "      <td>0.0419</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0319</td>\n",
              "      <td>0.0138</td>\n",
              "      <td>0.0538</td>\n",
              "      <td>0.0367</td>\n",
              "      <td>0.0501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.7334</td>\n",
              "      <td>0.6889</td>\n",
              "      <td>0.9119</td>\n",
              "      <td>0.3911</td>\n",
              "      <td>0.6206</td>\n",
              "      <td>0.5820</td>\n",
              "      <td>0.8042</td>\n",
              "      <td>0.3070</td>\n",
              "      <td>0.5555</td>\n",
              "      <td>0.5278</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3991</td>\n",
              "      <td>0.3800</td>\n",
              "      <td>0.4061</td>\n",
              "      <td>0.3997</td>\n",
              "      <td>0.4084</td>\n",
              "      <td>0.4177</td>\n",
              "      <td>0.4059</td>\n",
              "      <td>0.4096</td>\n",
              "      <td>0.4064</td>\n",
              "      <td>0.4106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8224</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9906</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8200</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9862</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 91 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        price_0   price_1   price_2   price_3   price_4   price_5   price_6  \\\n",
              "count 1200.0000 1200.0000 1200.0000 1200.0000 1200.0000 1200.0000 1200.0000   \n",
              "mean     0.1419    0.1183    0.3868   -0.1542    0.1316    0.1095    0.3698   \n",
              "std      0.6372    0.6124    0.5525    0.5935    0.5528    0.5417    0.4996   \n",
              "min     -1.0000   -0.9991   -0.9590   -1.0000   -1.0000   -0.9986   -0.9590   \n",
              "25%     -0.4211   -0.4261   -0.1056   -0.7430   -0.3686   -0.3612   -0.0497   \n",
              "50%      0.2509    0.1884    0.5193   -0.0969    0.2314    0.1769    0.4765   \n",
              "75%      0.7334    0.6889    0.9119    0.3911    0.6206    0.5820    0.8042   \n",
              "max      1.0000    1.0000    1.0000    0.8224    1.0000    0.9906    1.0000   \n",
              "\n",
              "        price_7   price_8   price_9    ...      change_15  change_16  \\\n",
              "count 1200.0000 1200.0000 1200.0000    ...      1200.0000  1200.0000   \n",
              "mean    -0.1635    0.1161    0.0969    ...         0.0103     0.0091   \n",
              "std      0.5345    0.5125    0.5085    ...         0.5245     0.5203   \n",
              "min     -1.0000   -1.0000   -0.9985    ...        -1.0000    -1.0000   \n",
              "25%     -0.6371   -0.3067   -0.3238    ...        -0.3786    -0.3606   \n",
              "50%     -0.1232    0.1854    0.1549    ...         0.0321     0.0386   \n",
              "75%      0.3070    0.5555    0.5278    ...         0.3991     0.3800   \n",
              "max      0.8200    1.0000    0.9862    ...         1.0000     1.0000   \n",
              "\n",
              "       change_17  change_18  change_19  change_20  change_21  change_22  \\\n",
              "count  1200.0000  1200.0000  1200.0000  1200.0000  1200.0000  1200.0000   \n",
              "mean      0.0291     0.0147     0.0193     0.0156     0.0099     0.0178   \n",
              "std       0.5195     0.5216     0.5202     0.5312     0.5292     0.5298   \n",
              "min      -1.0000    -1.0000    -1.0000    -1.0000    -1.0000    -1.0000   \n",
              "25%      -0.3430    -0.3613    -0.3517    -0.3861    -0.3787    -0.3619   \n",
              "50%       0.0419     0.0284     0.0235     0.0319     0.0138     0.0538   \n",
              "75%       0.4061     0.3997     0.4084     0.4177     0.4059     0.4096   \n",
              "max       1.0000     1.0000     1.0000     1.0000     1.0000     1.0000   \n",
              "\n",
              "       change_23  change_24  \n",
              "count  1200.0000  1200.0000  \n",
              "mean      0.0106     0.0274  \n",
              "std       0.5230     0.5245  \n",
              "min      -1.0000    -1.0000  \n",
              "25%      -0.3612    -0.3486  \n",
              "50%       0.0367     0.0501  \n",
              "75%       0.4064     0.4106  \n",
              "max       1.0000     1.0000  \n",
              "\n",
              "[8 rows x 91 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "metadata": {
        "id": "bokTWI-RoM9N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#_ = training_examples.hist(bins=20, figsize=(18, 12), xlabelsize=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u55gYB9fuofn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "fa90b363-81f5-4ae7-ac06-91d0cdd83035"
      },
      "cell_type": "code",
      "source": [
        "training_targets.describe()"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count   1200.0000\n",
              "mean       3.5533\n",
              "std        2.0686\n",
              "min        0.0000\n",
              "25%        2.0000\n",
              "50%        4.0000\n",
              "75%        5.0000\n",
              "max        7.0000\n",
              "Name: change_25, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 336
        }
      ]
    },
    {
      "metadata": {
        "id": "iVJeDDc_tynt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "5e7cb664-2b8f-460c-dff7-13239211b437"
      },
      "cell_type": "code",
      "source": [
        "_ = training_targets.hist(bins=20, figsize=(18, 12), xlabelsize=10)"
      ],
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBIAAAKrCAYAAABMTa5BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0d2e495bd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ukdD-ETjgswG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "ef770384-4584-4f91-aa88-35916a9108f5"
      },
      "cell_type": "code",
      "source": [
        "validation_targets, validation_examples = parse_labels_and_features(google_data[1200:1500], price_lookback, volume_lookback, change_lookback)\n",
        "validation_examples.describe()"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price_0</th>\n",
              "      <th>price_1</th>\n",
              "      <th>price_2</th>\n",
              "      <th>price_3</th>\n",
              "      <th>price_4</th>\n",
              "      <th>price_5</th>\n",
              "      <th>price_6</th>\n",
              "      <th>price_7</th>\n",
              "      <th>price_8</th>\n",
              "      <th>price_9</th>\n",
              "      <th>...</th>\n",
              "      <th>change_15</th>\n",
              "      <th>change_16</th>\n",
              "      <th>change_17</th>\n",
              "      <th>change_18</th>\n",
              "      <th>change_19</th>\n",
              "      <th>change_20</th>\n",
              "      <th>change_21</th>\n",
              "      <th>change_22</th>\n",
              "      <th>change_23</th>\n",
              "      <th>change_24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "      <td>300.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0831</td>\n",
              "      <td>0.0686</td>\n",
              "      <td>0.3164</td>\n",
              "      <td>-0.2322</td>\n",
              "      <td>0.0527</td>\n",
              "      <td>0.0301</td>\n",
              "      <td>0.3020</td>\n",
              "      <td>-0.2675</td>\n",
              "      <td>0.0372</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0436</td>\n",
              "      <td>0.0586</td>\n",
              "      <td>-0.0266</td>\n",
              "      <td>0.0353</td>\n",
              "      <td>0.0259</td>\n",
              "      <td>0.0365</td>\n",
              "      <td>0.0524</td>\n",
              "      <td>0.0248</td>\n",
              "      <td>0.0515</td>\n",
              "      <td>-0.0139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.6611</td>\n",
              "      <td>0.6267</td>\n",
              "      <td>0.5722</td>\n",
              "      <td>0.5808</td>\n",
              "      <td>0.5599</td>\n",
              "      <td>0.5502</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.5223</td>\n",
              "      <td>0.5147</td>\n",
              "      <td>0.5109</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5115</td>\n",
              "      <td>0.5318</td>\n",
              "      <td>0.5396</td>\n",
              "      <td>0.5351</td>\n",
              "      <td>0.5437</td>\n",
              "      <td>0.5157</td>\n",
              "      <td>0.5145</td>\n",
              "      <td>0.5089</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.9529</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.9824</td>\n",
              "      <td>-0.9877</td>\n",
              "      <td>-0.9573</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-0.9966</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.5258</td>\n",
              "      <td>-0.5138</td>\n",
              "      <td>-0.2218</td>\n",
              "      <td>-0.7927</td>\n",
              "      <td>-0.4797</td>\n",
              "      <td>-0.4837</td>\n",
              "      <td>-0.1210</td>\n",
              "      <td>-0.7446</td>\n",
              "      <td>-0.3833</td>\n",
              "      <td>-0.4040</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.3116</td>\n",
              "      <td>-0.3284</td>\n",
              "      <td>-0.4233</td>\n",
              "      <td>-0.3787</td>\n",
              "      <td>-0.3927</td>\n",
              "      <td>-0.3023</td>\n",
              "      <td>-0.2869</td>\n",
              "      <td>-0.3422</td>\n",
              "      <td>-0.3551</td>\n",
              "      <td>-0.4384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.2038</td>\n",
              "      <td>0.1575</td>\n",
              "      <td>0.4235</td>\n",
              "      <td>-0.2360</td>\n",
              "      <td>0.0964</td>\n",
              "      <td>0.0724</td>\n",
              "      <td>0.3672</td>\n",
              "      <td>-0.2589</td>\n",
              "      <td>0.0675</td>\n",
              "      <td>-0.0253</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0417</td>\n",
              "      <td>0.0359</td>\n",
              "      <td>-0.0230</td>\n",
              "      <td>0.0519</td>\n",
              "      <td>0.0482</td>\n",
              "      <td>0.0391</td>\n",
              "      <td>0.1128</td>\n",
              "      <td>-0.0117</td>\n",
              "      <td>0.0750</td>\n",
              "      <td>0.0436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.6844</td>\n",
              "      <td>0.6635</td>\n",
              "      <td>0.8456</td>\n",
              "      <td>0.3478</td>\n",
              "      <td>0.5538</td>\n",
              "      <td>0.5020</td>\n",
              "      <td>0.7732</td>\n",
              "      <td>0.1535</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.4379</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3989</td>\n",
              "      <td>0.4734</td>\n",
              "      <td>0.3754</td>\n",
              "      <td>0.4296</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.3811</td>\n",
              "      <td>0.4129</td>\n",
              "      <td>0.4039</td>\n",
              "      <td>0.4384</td>\n",
              "      <td>0.4089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9927</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9777</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7617</td>\n",
              "      <td>0.9891</td>\n",
              "      <td>0.9651</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 91 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       price_0  price_1  price_2  price_3  price_4  price_5  price_6  price_7  \\\n",
              "count 300.0000 300.0000 300.0000 300.0000 300.0000 300.0000 300.0000 300.0000   \n",
              "mean    0.0831   0.0686   0.3164  -0.2322   0.0527   0.0301   0.3020  -0.2675   \n",
              "std     0.6611   0.6267   0.5722   0.5808   0.5599   0.5502   0.5144   0.5223   \n",
              "min    -1.0000  -1.0000  -0.9529  -1.0000  -0.9824  -0.9877  -0.9573  -1.0000   \n",
              "25%    -0.5258  -0.5138  -0.2218  -0.7927  -0.4797  -0.4837  -0.1210  -0.7446   \n",
              "50%     0.2038   0.1575   0.4235  -0.2360   0.0964   0.0724   0.3672  -0.2589   \n",
              "75%     0.6844   0.6635   0.8456   0.3478   0.5538   0.5020   0.7732   0.1535   \n",
              "max     1.0000   0.9927   1.0000   0.7551   1.0000   0.9777   1.0000   0.7617   \n",
              "\n",
              "       price_8  price_9    ...      change_15  change_16  change_17  \\\n",
              "count 300.0000 300.0000    ...       300.0000   300.0000   300.0000   \n",
              "mean    0.0372   0.0012    ...         0.0436     0.0586    -0.0266   \n",
              "std     0.5147   0.5109    ...         0.5115     0.5318     0.5396   \n",
              "min    -1.0000  -0.9966    ...        -1.0000    -1.0000    -1.0000   \n",
              "25%    -0.3833  -0.4040    ...        -0.3116    -0.3284    -0.4233   \n",
              "50%     0.0675  -0.0253    ...         0.0417     0.0359    -0.0230   \n",
              "75%     0.4604   0.4379    ...         0.3989     0.4734     0.3754   \n",
              "max     0.9891   0.9651    ...         1.0000     1.0000     1.0000   \n",
              "\n",
              "       change_18  change_19  change_20  change_21  change_22  change_23  \\\n",
              "count   300.0000   300.0000   300.0000   300.0000   300.0000   300.0000   \n",
              "mean      0.0353     0.0259     0.0365     0.0524     0.0248     0.0515   \n",
              "std       0.5351     0.5437     0.5157     0.5145     0.5089     0.5375   \n",
              "min      -1.0000    -1.0000    -1.0000    -1.0000    -1.0000    -1.0000   \n",
              "25%      -0.3787    -0.3927    -0.3023    -0.2869    -0.3422    -0.3551   \n",
              "50%       0.0519     0.0482     0.0391     0.1128    -0.0117     0.0750   \n",
              "75%       0.4296     0.4366     0.3811     0.4129     0.4039     0.4384   \n",
              "max       1.0000     1.0000     1.0000     1.0000     1.0000     1.0000   \n",
              "\n",
              "       change_24  \n",
              "count   300.0000  \n",
              "mean     -0.0139  \n",
              "std       0.5452  \n",
              "min      -1.0000  \n",
              "25%      -0.4384  \n",
              "50%       0.0436  \n",
              "75%       0.4089  \n",
              "max       1.0000  \n",
              "\n",
              "[8 rows x 91 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 338
        }
      ]
    },
    {
      "metadata": {
        "id": "XXZNf_Big6YQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns(price_lookback, volume_lookback, change_lookback):\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  return set([tf.feature_column.numeric_column('features', shape=1+price_lookback*4+volume_lookback+change_lookback)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQTuKLN9hu4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2b15e8f4-62d4-4f01-d75b-0e0239e4f302"
      },
      "cell_type": "code",
      "source": [
        "def create_training_input_fn(features, labels, batch_size, num_epochs=None, shuffle=True):\n",
        "  def _input_fn(num_epochs=None, shuffle=True):\n",
        "    # Input pipelines are reset with each call to .train(). To ensure model\n",
        "    # gets a good sampling of data, even when number of steps is small, we \n",
        "    # shuffle all the data before creating the Dataset object\n",
        "    idx = np.random.permutation(features.index)\n",
        "    raw_features = {\"features\":features.reindex(idx)}\n",
        "    raw_targets = np.array(labels[idx])\n",
        "   \n",
        "    ds = Dataset.from_tensor_slices((raw_features,raw_targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn\n",
        "\n",
        "# Validate method\n",
        "create_training_input_fn(training_examples, training_targets, 10)(5)"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'features': <tf.Tensor 'IteratorGetNext_15:0' shape=(?, 91) dtype=float64>},\n",
              " <tf.Tensor 'IteratorGetNext_15:1' shape=(?,) dtype=int64>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 340
        }
      ]
    },
    {
      "metadata": {
        "id": "eWSFsWfspAJb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_predict_input_fn(features, labels, batch_size):\n",
        "  def _input_fn():\n",
        "    raw_features = {\"features\": features.values}\n",
        "    raw_targets = np.array(labels)\n",
        "    \n",
        "    ds = Dataset.from_tensor_slices((raw_features, raw_targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size)\n",
        "    \n",
        "        \n",
        "    # Return the next batch of data.\n",
        "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
        "    return feature_batch, label_batch\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9o2nRkPqaUr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_nn_classification_model(\n",
        "    learning_rate,\n",
        "    regularization_strength,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    hidden_units,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets,\n",
        "    price_lookback,\n",
        "    volume_lookback,\n",
        "    change_lookback):\n",
        "  \"\"\"Trains a neural network classification model for the MNIST digits dataset.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  a plot of the training and validation loss over time, as well as a confusion\n",
        "  matrix.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: An `int`, the learning rate to use.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    hidden_units: A `list` of int values, specifying the number of neurons in each layer.\n",
        "    training_examples: A `DataFrame` containing the training features.\n",
        "    training_targets: A `DataFrame` containing the training labels.\n",
        "    validation_examples: A `DataFrame` containing the validation features.\n",
        "    validation_targets: A `DataFrame` containing the validation labels.\n",
        "      \n",
        "  Returns:\n",
        "    The trained `DNNClassifier` object.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 20\n",
        "  # Caution: input pipelines are reset with each call to train. \n",
        "  # If the number of steps is small, your model may never see most of the data.  \n",
        "  # So with multiple `.train` calls like this you may want to control the length \n",
        "  # of training with num_epochs passed to the input_fn. Or, you can do a really-big shuffle, \n",
        "  # or since it's in-memory data, shuffle all the data in the `input_fn`.\n",
        "  steps_per_period = steps / periods  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create the input functions.\n",
        "  predict_training_input_fn = create_predict_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  predict_validation_input_fn = create_predict_input_fn(\n",
        "    validation_examples, validation_targets, batch_size)\n",
        "  training_input_fn = create_training_input_fn(\n",
        "    training_examples, training_targets, batch_size)\n",
        "  \n",
        "  # Create feature columns.\n",
        "  feature_columns = [tf.feature_column.numeric_column('features', shape=1+price_lookback*4+volume_lookback+change_lookback)]\n",
        "\n",
        "  # Create a DNNClassifier object.\n",
        "  #my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate, l1_regularization_strength=regularization_strength)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  classifier = tf.estimator.DNNClassifier(\n",
        "      feature_columns=feature_columns,\n",
        "      n_classes=8,\n",
        "      hidden_units=hidden_units,\n",
        "      optimizer=my_optimizer,\n",
        "      config=tf.contrib.learn.RunConfig(keep_checkpoint_max=1)\n",
        "  )\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print \"Training model...\"\n",
        "  print \"LogLoss error (on validation data):\"\n",
        "  training_errors = []\n",
        "  validation_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "  \n",
        "    # Take a break and compute probabilities.\n",
        "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
        "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
        "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,8)\n",
        "        \n",
        "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
        "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
        "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,8)    \n",
        "    \n",
        "    # Compute training and validation errors.\n",
        "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
        "    # Occasionally print the current loss.\n",
        "    print \"  period %02d : %0.2f\" % (period, validation_log_loss)\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_errors.append(training_log_loss)\n",
        "    validation_errors.append(validation_log_loss)\n",
        "  print \"Model training finished.\"\n",
        "  # Remove event files to save disk space.\n",
        "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
        "  \n",
        "  # Calculate final predictions (not probabilities, as above).\n",
        "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
        "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
        "  \n",
        "  \n",
        "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
        "  print \"Final accuracy (on validation data): %0.2f\" % accuracy  \n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.plot(training_errors, label=\"training\")\n",
        "  plt.plot(validation_errors, label=\"validation\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  # Output a plot of the confusion matrix.\n",
        "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
        "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
        "  # in each class).\n",
        "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
        "  ax.set_aspect(1)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "  plt.show()\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rANH6YCHrGrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1143
        },
        "outputId": "8fa19853-4e8e-41b1-fb1a-786b31dcb5b1"
      },
      "cell_type": "code",
      "source": [
        "classifier = train_nn_classification_model(\n",
        "    learning_rate=0.003,\n",
        "    regularization_strength=0.03,\n",
        "    steps=10000,\n",
        "    batch_size=70,\n",
        "    hidden_units=[50, 40, 30, 20, 10],\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets,\n",
        "    price_lookback=price_lookback,\n",
        "    volume_lookback=volume_lookback,\n",
        "    change_lookback=change_lookback)"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "LogLoss error (on validation data):\n",
            "  period 00 : 27.75\n",
            "  period 01 : 27.75\n",
            "  period 02 : 27.75\n",
            "  period 03 : 27.75\n",
            "  period 04 : 27.75\n",
            "  period 05 : 27.75\n",
            "  period 06 : 27.75\n",
            "  period 07 : 27.75\n",
            "  period 08 : 27.75\n",
            "  period 09 : 27.75\n",
            "  period 10 : 27.75\n",
            "  period 11 : 27.75\n",
            "  period 12 : 27.75\n",
            "  period 13 : 27.75\n",
            "  period 14 : 27.75\n",
            "  period 15 : 27.75\n",
            "  period 16 : 27.75\n",
            "  period 17 : 27.75\n",
            "  period 18 : 27.75\n",
            "  period 19 : 27.75\n",
            "Model training finished.\n",
            "Final accuracy (on validation data): 0.20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAGCI/w+QzTI0xgQGcwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0d24e27d50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAFnCAYAAACM3c9QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0d1ac2aed0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}